# ç«¶é¦¬äºˆæ¸¬MLã‚·ã‚¹ãƒ†ãƒ  ä»•æ§˜æ›¸

## 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### 1.1 ç›®çš„
ç«¶é¦¬ã®é¦¬åˆ¸è³¼å…¥ã‚’æ”¯æ´ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€å›åç‡100%ä»¥ä¸Šã‚’ç›®æŒ‡ã™ã€‚

### 1.2 å¯¾è±¡é¦¬åˆ¸
- **ä¸»å¯¾è±¡**: å˜å‹ãƒ»è¤‡å‹
- **äºˆæ¸¬å†…å®¹**: å„é¦¬ã®3ç€ä»¥å†…ã«å…¥ã‚‹ç¢ºç‡ã‚’äºˆæ¸¬
- **è³¼å…¥åˆ¤æ–­**: äºˆæ¸¬ç¢ºç‡ã¨ã‚ªãƒƒã‚ºã‚’è€ƒæ…®ã—ã€æœŸå¾…å›åç‡ãŒé«˜ã„é¦¬åˆ¸ã‚’é¸å®š

### 1.3 ç›®æ¨™æŒ‡æ¨™
- **å›åç‡**: 100%ä»¥ä¸Š
- **è©•ä¾¡æŒ‡æ¨™**: NDCG@3, Recall@3
- **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“**: æœ€ä½6ãƒ¶æœˆä»¥ä¸Š

### 1.4 æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
- **è¨€èª**: Python 3.9+
- **æ©Ÿæ¢°å­¦ç¿’**: LightGBM (Learning to Rank)
- **é–‹ç™ºç’°å¢ƒ**: Jupyter Notebook (EDA), ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ (æœ¬ç•ª)
- **ã‚¯ãƒ©ã‚¦ãƒ‰**: GCP (Cloud Storage, BigQuery, Cloud Run, Cloud Scheduler)
- **é€šçŸ¥**: ãƒ¡ãƒ¼ãƒ« (SendGrid/Gmail API), LINE (LINE Notify)
- **å¯è¦–åŒ–**: Streamlit ã¾ãŸã¯ Dash (Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰)

---

## 2. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 2.1 å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Layer                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ãƒ­ãƒ¼ã‚«ãƒ«] downloader scripts â†’ [GCS] raw data bucket           â”‚
â”‚  [GCS] â†’ [Cloud Functions] â†’ [BigQuery] ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Feature Engineering Layer                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [BigQuery] SQL/Python â†’ ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ                      â”‚
â”‚  - éå»èµ°é›†è¨ˆã€Target Encodingã€ç›¸å¯¾æŒ‡æ¨™ãªã©                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Model Training Layer                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Jupyter Notebook] EDA & ãƒ¢ãƒ‡ãƒ«é–‹ç™º                             â”‚
â”‚  [Python Script] LightGBM ãƒ©ãƒ³ã‚¯å­¦ç¿’                             â”‚
â”‚  [GCS] ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Prediction & Operation Layer                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Cloud Scheduler] å®šæœŸå®Ÿè¡Œãƒˆãƒªã‚¬ãƒ¼                              â”‚
â”‚  [Cloud Run] äºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ                                  â”‚
â”‚  [BigQuery] äºˆæ¸¬çµæœä¿å­˜                                         â”‚
â”‚  [Streamlit on Cloud Run] Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰                      â”‚
â”‚  [Cloud Functions] ãƒ¡ãƒ¼ãƒ«/LINEé€šçŸ¥                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 GCPãƒªã‚½ãƒ¼ã‚¹æ§‹æˆ

#### 2.2.1 Cloud Storage (GCS)
- **ãƒã‚±ãƒƒãƒˆæ§‹æˆ**:
  - `gs://keiba-raw-data/`: JRDBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”Ÿãƒ‡ãƒ¼ã‚¿ (lzh, txt, csv)
  - `gs://keiba-processed-data/`: åŠ å·¥æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
  - `gs://keiba-models/`: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
  - `gs://keiba-predictions/`: äºˆæ¸¬çµæœ

#### 2.2.2 BigQuery
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹æˆ**:
  - `raw`: ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ« (JRDBå„ç¨®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—)
  - `features`: ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«
  - `predictions`: äºˆæ¸¬çµæœãƒ†ãƒ¼ãƒ–ãƒ«
  - `backtests`: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãƒ†ãƒ¼ãƒ–ãƒ«

#### 2.2.3 Cloud Functions
- **é–¢æ•°ä¸€è¦§**:
  - `gcs_to_bigquery`: GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’BigQueryã«ãƒ­ãƒ¼ãƒ‰
  - `send_notification`: äºˆæ¸¬çµæœã‚’ãƒ¡ãƒ¼ãƒ«/LINEã§é€šçŸ¥

#### 2.2.4 Cloud Run
- **ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§**:
  - `prediction-service`: äºˆæ¸¬å®Ÿè¡Œã‚µãƒ¼ãƒ“ã‚¹
  - `dashboard-service`: Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (Streamlit)

#### 2.2.5 Cloud Scheduler
- **ã‚¸ãƒ§ãƒ–ä¸€è¦§**:
  - `daily-data-download`: æ¯æ—¥AM 6:00 ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  - `pre-race-prediction`: ãƒ¬ãƒ¼ã‚¹å‰æ—¥ PM 9:00 äºˆæ¸¬å®Ÿè¡Œ
  - `race-day-prediction`: ãƒ¬ãƒ¼ã‚¹å½“æ—¥ AM 8:00 äºˆæ¸¬æ›´æ–°

---

## 3. ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 3.1 ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ•ãƒ­ãƒ¼

#### 3.1.1 ãƒ­ãƒ¼ã‚«ãƒ« â†’ GCS
```bash
# 1. ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (æ—¢å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨)
cd downloader
sh download_all_from_date.sh

# 2. GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
gsutil -m rsync -r ../downloaded_files/ gs://keiba-raw-data/
```

#### 3.1.2 è‡ªå‹•åŒ– (Cloud Scheduler + Cloud Run)
- **ãƒˆãƒªã‚¬ãƒ¼**: æ¯æ—¥AM 6:00
- **å‡¦ç†**:
  1. Cloud Runã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
  2. GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  3. Cloud FunctionsãŒãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã€BigQueryã«ãƒ­ãƒ¼ãƒ‰

### 3.2 BigQueryãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆ

#### 3.2.1 rawãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

##### ãƒ†ãƒ¼ãƒ–ãƒ«: `raw.race_info` (BAA: ç•ªçµ„ãƒ‡ãƒ¼ã‚¿)
```sql
CREATE TABLE raw.race_info (
  race_id STRING NOT NULL,          -- ãƒ¬ãƒ¼ã‚¹ID (å ´æ‰€ã‚³ãƒ¼ãƒ‰ + é–‹å‚¬å› + æ—¥æ¬¡ + ãƒ¬ãƒ¼ã‚¹ç•ªå·)
  race_date DATE NOT NULL,          -- é–‹å‚¬æ—¥
  venue_code STRING,                -- ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
  race_number INT64,                -- ãƒ¬ãƒ¼ã‚¹ç•ªå·
  course_type STRING,               -- èŠ/ãƒ€ãƒ¼ãƒˆ
  distance INT64,                   -- è·é›¢
  direction STRING,                 -- å³/å·¦
  race_class STRING,                -- ã‚¯ãƒ©ã‚¹ (G1/G2/OP/1600ä¸‡ä¸‹ç­‰)
  age_condition STRING,             -- å¹´é½¢æ¡ä»¶
  sex_condition STRING,             -- æ€§åˆ¥æ¡ä»¶
  weather STRING,                   -- å¤©å€™
  track_condition STRING,           -- é¦¬å ´çŠ¶æ…‹
  num_horses INT64,                 -- å‡ºèµ°é ­æ•°
  -- ãã®ä»–ã®ãƒ¬ãƒ¼ã‚¹æ¡ä»¶...
  PRIMARY KEY (race_id) NOT ENFORCED
) PARTITION BY race_date;
```

##### ãƒ†ãƒ¼ãƒ–ãƒ«: `raw.horse_results` (KYF: ç«¶èµ°é¦¬ãƒ‡ãƒ¼ã‚¿ + éå»æˆç¸¾)
```sql
CREATE TABLE raw.horse_results (
  race_id STRING NOT NULL,
  horse_id STRING NOT NULL,         -- é¦¬ID
  horse_name STRING,                -- é¦¬å
  bracket_number INT64,             -- æ ç•ª
  horse_number INT64,               -- é¦¬ç•ª
  finish_position INT64,            -- ç€é †
  finish_time FLOAT64,              -- èµ°ç ´ã‚¿ã‚¤ãƒ 
  last_3f_time FLOAT64,             -- ä¸ŠãŒã‚Š3F
  passing_order STRING,             -- é€šéé †
  odds FLOAT64,                     -- ã‚ªãƒƒã‚º
  popularity INT64,                 -- äººæ°—
  weight INT64,                     -- æ–¤é‡
  jockey_id STRING,                 -- é¨æ‰‹ID
  jockey_name STRING,               -- é¨æ‰‹å
  trainer_id STRING,                -- èª¿æ•™å¸«ID
  trainer_name STRING,              -- èª¿æ•™å¸«å
  horse_weight INT64,               -- é¦¬ä½“é‡
  horse_weight_diff INT64,          -- é¦¬ä½“é‡å¢—æ¸›
  -- IDMã€å„ç¨®æŒ‡æ•°...
  idm FLOAT64,
  -- ãã®ä»–ã®KYFãƒ‡ãƒ¼ã‚¿...
  PRIMARY KEY (race_id, horse_id) NOT ENFORCED
) PARTITION BY DATE(race_id);
```

##### ãƒ†ãƒ¼ãƒ–ãƒ«: `raw.pedigree` (è¡€çµ±ãƒ‡ãƒ¼ã‚¿)
```sql
CREATE TABLE raw.pedigree (
  horse_id STRING PRIMARY KEY NOT ENFORCED,
  sire_id STRING,                   -- ç¨®ç‰¡é¦¬ID
  sire_name STRING,                 -- ç¨®ç‰¡é¦¬å
  dam_sire_id STRING,               -- æ¯çˆ¶ID
  dam_sire_name STRING,             -- æ¯çˆ¶å
  sire_line STRING                  -- çˆ¶ç³»çµ±
);
```

##### ãƒ†ãƒ¼ãƒ–ãƒ«: `raw.odds` (ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿)
```sql
CREATE TABLE raw.odds (
  race_id STRING NOT NULL,
  horse_id STRING NOT NULL,
  odds_type STRING,                 -- å˜å‹/è¤‡å‹
  odds_value FLOAT64,               -- ã‚ªãƒƒã‚ºå€¤
  odds_timestamp TIMESTAMP,         -- å–å¾—æ™‚åˆ»
  PRIMARY KEY (race_id, horse_id, odds_type, odds_timestamp) NOT ENFORCED
) PARTITION BY DATE(race_id);
```

#### 3.2.2 featuresãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

##### ãƒ†ãƒ¼ãƒ–ãƒ«: `features.training_data`
```sql
CREATE TABLE features.training_data (
  race_id STRING NOT NULL,
  horse_id STRING NOT NULL,
  race_date DATE NOT NULL,

  -- ç›®çš„å¤‰æ•°
  target_place BOOL,                -- 3ç€ä»¥å†… (1/0)
  finish_position INT64,            -- ç€é † (ãƒ©ãƒ³ã‚¯å­¦ç¿’ç”¨)

  -- åŸºæœ¬æƒ…å ±
  venue_code STRING,
  race_number INT64,
  course_type STRING,
  distance INT64,
  track_condition STRING,
  num_horses INT64,
  bracket_number INT64,
  horse_number INT64,
  weight INT64,

  -- éå»èµ°é›†è¨ˆç‰¹å¾´ (è©³ç´°ã¯ML_FEATURE.mdå‚ç…§)
  past_3_avg_position FLOAT64,
  past_5_avg_position FLOAT64,
  past_10_avg_position FLOAT64,
  past_3_avg_last3f FLOAT64,
  past_5_avg_last3f FLOAT64,

  -- æ¡ä»¶é©æ€§
  turf_win_rate FLOAT64,
  dirt_win_rate FLOAT64,
  distance_category_win_rate FLOAT64,
  venue_win_rate FLOAT64,
  heavy_track_win_rate FLOAT64,

  -- é¨æ‰‹ãƒ»èª¿æ•™å¸«
  jockey_id STRING,
  jockey_win_rate FLOAT64,
  jockey_venue_win_rate FLOAT64,
  trainer_id STRING,
  trainer_win_rate FLOAT64,

  -- Target Encoding (æ™‚ç³»åˆ—OOF)
  jockey_te_place FLOAT64,
  trainer_te_place FLOAT64,
  sire_te_place FLOAT64,
  dam_sire_te_place FLOAT64,

  -- ç›¸å¯¾æŒ‡æ¨™ (ãƒ¬ãƒ¼ã‚¹å†…)
  weight_rank INT64,
  ability_rank INT64,
  last3f_rank INT64,

  -- å±•é–‹äºˆæ¸¬
  front_runner_count INT64,
  expected_pace_score FLOAT64,

  -- ã‚ªãƒƒã‚º (å‰æ—¥ãƒ»å½“æ—¥)
  odds_yesterday FLOAT64,
  odds_today FLOAT64,

  -- ... (ML_FEATURE.mdã®ä»–ã®ç‰¹å¾´é‡)

  PRIMARY KEY (race_id, horse_id) NOT ENFORCED
) PARTITION BY race_date;
```

---

## 4. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

### 4.1 ç‰¹å¾´é‡ä¸€è¦§
**ãƒ•ã‚¡ã‚¤ãƒ«**: @doc/ML_FEATURE.md

ä¸»è¦ã‚«ãƒ†ã‚´ãƒªï¼š
1. **ãƒ™ãƒ¼ã‚¹ç‰¹å¾´**: ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ã€é¦¬å ´ã€å¤©å€™
2. **éå»èµ°é›†è¨ˆ**: Nèµ°å¹³å‡ã€æœ€å¤§å€¤ã€ãƒˆãƒ¬ãƒ³ãƒ‰
3. **æ¡ä»¶é©æ€§**: è·é›¢/ã‚³ãƒ¼ã‚¹/é¦¬å ´/å­£ç¯€é©æ€§
4. **è¿‘æ³**: ä¼‘é¤Šæ—¥æ•°ã€å©ãä½•èµ°ç›®
5. **ç›¸å¯¾æŒ‡æ¨™**: ãƒ¬ãƒ¼ã‚¹å†…é †ä½ã€å¹³å‡ã¨ã®å·®
6. **å±•é–‹äºˆæ¸¬**: é€ƒã’å€™è£œæ•°ã€äºˆæƒ³ãƒšãƒ¼ã‚¹
7. **äººçš„è¦ç´ **: é¨æ‰‹/èª¿æ•™å¸«/ã‚³ãƒ³ãƒ“æˆç¸¾
8. **è¡€çµ±**: ç¨®ç‰¡é¦¬/æ¯çˆ¶é©æ€§
9. **èª¿æ•™ãƒ»é¦¬ä½“**: èª¿æ•™ã‚¿ã‚¤ãƒ ã€é¦¬ä½“é‡å¢—æ¸›
10. **ã‚ªãƒƒã‚º**: å‰æ—¥/å½“æ—¥ã‚ªãƒƒã‚ºã€å¤‰å‹•é‡
11. **Target Encoding**: æ™‚ç³»åˆ—OOF + å¹³æ»‘åŒ–
12. **é«˜æ¬¡ç‰¹å¾´**: äº¤äº’ä½œç”¨ã€å·®åˆ†ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°

### 4.2 å®Ÿè£…å„ªå…ˆé †ä½

#### Phase 1: åŸºæœ¬ç‰¹å¾´ (æœ€å„ªå…ˆ)
1. éå»Nèµ°ã®åŸºæœ¬çµ±è¨ˆ (ç€é †/ç€å·®/ä¸ŠãŒã‚Š/é€šéé †)
2. ä¼‘é¤Šæ—¥æ•°ã€è·é›¢å¤‰æ›´
3. æ¡ä»¶é©æ€§ (èŠãƒ€ãƒ»è·é›¢å¸¯ãƒ»ç«¶é¦¬å ´ãƒ»é¦¬å ´)

#### Phase 2: ã‚³ã‚¢ç‰¹å¾´
4. é¨æ‰‹/èª¿æ•™å¸«/ç¨®ç‰¡é¦¬ã®Target Encoding
5. å±•é–‹äºˆæ¸¬ (å…ˆè¡ŒåŠ›é›†è¨ˆã€é€ƒã’å€™è£œæ•°)

#### Phase 3: é«˜åº¦ç‰¹å¾´
6. è‡ªä½œèƒ½åŠ›æŒ‡æ•° + ãƒ¬ãƒ¼ã‚¹å†…ç›¸å¯¾æŒ‡æ¨™
7. èª¿æ•™/é¦¬ä½“é‡/ã‚ªãƒƒã‚º

### 4.3 Target Encodingå®Ÿè£…

#### 4.3.1 æ™‚ç³»åˆ—OOF (Out-of-Fold)
```python
def create_te_oof(df, category_col, target_col, date_col):
    """
    æ™‚ç³»åˆ—ã‚’è€ƒæ…®ã—ãŸTarget Encoding
    å„è¡Œã®TEã¯ã€ãã®è¡Œã‚ˆã‚Šéå»ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‹ã‚‰è¨ˆç®—
    """
    df = df.sort_values(date_col)
    df['te_' + category_col] = np.nan

    for idx in df.index:
        current_date = df.loc[idx, date_col]
        category = df.loc[idx, category_col]

        # éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿
        past_data = df[df[date_col] < current_date]
        past_category = past_data[past_data[category_col] == category]

        if len(past_category) > 0:
            # å¹³æ»‘åŒ– (Smoothing)
            global_mean = past_data[target_col].mean()
            category_mean = past_category[target_col].mean()
            count = len(past_category)
            m = 10  # å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

            te_value = (count * category_mean + m * global_mean) / (count + m)
            df.loc[idx, 'te_' + category_col] = te_value
        else:
            df.loc[idx, 'te_' + category_col] = df[target_col].mean()

    return df
```

### 4.4 ãƒªãƒ¼ã‚¯å¯¾ç­–ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ç™ºèµ°å¾Œã«ç¢ºå®šã™ã‚‹æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„ (ç¢ºå®šã‚ªãƒƒã‚ºã€ç¢ºå®šé¦¬ä½“é‡ãªã©)
- [ ] Target Encodingã¯æ™‚ç³»åˆ—OOFã§ä½œæˆ
- [ ] åŒä¸€ãƒ¬ãƒ¼ã‚¹å†…ã®æƒ…å ±æ¼æ´©ãŒãªã„
- [ ] æ™‚ç³»åˆ—åˆ†å‰²ã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿæ–½

---

## 5. ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ

### 5.1 LightGBM ãƒ©ãƒ³ã‚¯å­¦ç¿’

#### 5.1.1 ãƒ¢ãƒ‡ãƒ«æ¦‚è¦
- **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: LightGBM LambdaRank
- **ç›®çš„é–¢æ•°**: `lambdarank`
- **è©•ä¾¡æŒ‡æ¨™**: `ndcg@3`
- **ã‚°ãƒ«ãƒ¼ãƒ—å˜ä½**: ãƒ¬ãƒ¼ã‚¹ID

#### 5.1.2 å®Ÿè£…ä¾‹
```python
import lightgbm as lgb

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
train_data = lgb.Dataset(
    X_train,
    label=y_train,  # ç€é † (1, 2, 3, ...)
    group=groups_train  # å„ãƒ¬ãƒ¼ã‚¹ã®é¦¬æ•° [18, 16, 15, ...]
)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
params = {
    'objective': 'lambdarank',
    'metric': 'ndcg',
    'ndcg_eval_at': [3],
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1,
    'seed': 42
}

# å­¦ç¿’
model = lgb.train(
    params,
    train_data,
    num_boost_round=1000,
    valid_sets=[valid_data],
    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]
)
```

### 5.2 æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

#### 5.2.1 åˆ†å‰²æ–¹æ³•
```python
# ä¾‹: æœˆæ¬¡åˆ†å‰²
# 2019/01-2023/06: å­¦ç¿’ç”¨
# 2023/07-2023/12: æ¤œè¨¼ç”¨
# 2024/01-2024/06: ãƒ†ã‚¹ãƒˆç”¨

def time_series_split(df, date_col, n_splits=5):
    """
    æ™‚ç³»åˆ—ã‚’è€ƒæ…®ã—ãŸã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²
    """
    df = df.sort_values(date_col)
    total_months = (df[date_col].max() - df[date_col].min()).days // 30
    fold_size = total_months // (n_splits + 1)

    for i in range(n_splits):
        train_end = df[date_col].min() + pd.DateOffset(months=fold_size * (i + 1))
        valid_end = train_end + pd.DateOffset(months=fold_size)

        train_idx = df[df[date_col] < train_end].index
        valid_idx = df[(df[date_col] >= train_end) & (df[date_col] < valid_end)].index

        yield train_idx, valid_idx
```

### 5.3 ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

#### 5.3.1 è©•ä¾¡æŒ‡æ¨™
1. **NDCG@3**: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®è³ªã‚’è©•ä¾¡
2. **Recall@3**: ä¸Šä½3é ­ã®ä¸­ã«è¤‡å‹åœå†…ã®é¦¬ãŒå«ã¾ã‚Œã‚‹å‰²åˆ
3. **å›åç‡**: å®Ÿéš›ã®æŠ•è³‡ã«åŸºã¥ãè©•ä¾¡
4. **çš„ä¸­ç‡**: 3ç€ä»¥å†…äºˆæ¸¬ã®ç²¾åº¦

#### 5.3.2 è©•ä¾¡å®Ÿè£…
```python
from sklearn.metrics import ndcg_score

def evaluate_model(y_true, y_pred, groups):
    """
    ãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–¢æ•°
    """
    results = []
    start = 0

    for group_size in groups:
        end = start + group_size
        race_true = y_true[start:end]
        race_pred = y_pred[start:end]

        # NDCG@3
        ndcg = ndcg_score([race_true], [race_pred], k=3)

        # Recall@3
        top3_pred = np.argsort(race_pred)[-3:]
        top3_true = np.where(race_true <= 3)[0]
        recall = len(set(top3_pred) & set(top3_true)) / min(3, len(top3_true))

        results.append({'ndcg@3': ndcg, 'recall@3': recall})
        start = end

    return pd.DataFrame(results).mean()
```

---

## 6. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­è¨ˆ

### 6.1 ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¦‚è¦
- **ç›®çš„**: éå»ãƒ‡ãƒ¼ã‚¿ã§å®Ÿéš›ã®æŠ•è³‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **æœŸé–“**: æœ€ä½6ãƒ¶æœˆä»¥ä¸Š
- **è©•ä¾¡**: å›åç‡ã€çš„ä¸­ç‡ã€æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³

### 6.2 æŠ•è³‡æˆ¦ç•¥

#### 6.2.1 KellyåŸºæº–ãƒ™ãƒ¼ã‚¹
```python
def kelly_criterion(win_prob, odds):
    """
    KellyåŸºæº–: æœ€é©è³­ã‘é‡‘æ¯”ç‡
    f* = (p * (odds - 1) - (1 - p)) / (odds - 1)
    """
    if odds <= 1:
        return 0
    kelly = (win_prob * (odds - 1) - (1 - win_prob)) / (odds - 1)
    return max(0, kelly)  # è² ã®å€¤ã¯è³­ã‘ãªã„

def fractional_kelly(win_prob, odds, fraction=0.25):
    """
    Fractional Kelly: ãƒªã‚¹ã‚¯èª¿æ•´
    """
    return kelly_criterion(win_prob, odds) * fraction
```

#### 6.2.2 æŠ•è³‡ãƒ«ãƒ¼ãƒ«
1. **é–¾å€¤è¨­å®š**: äºˆæ¸¬ç¢ºç‡ > é–¾å€¤ ã®é¦¬ã®ã¿è³¼å…¥
2. **æœŸå¾…å€¤ãƒ•ã‚£ãƒ«ã‚¿**: æœŸå¾…å›åç‡ = äºˆæ¸¬ç¢ºç‡ Ã— ã‚ªãƒƒã‚º > 1.2 ã®é¦¬ã®ã¿
3. **è³­ã‘é‡‘é…åˆ†**: Fractional Kelly (25%)
4. **1ãƒ¬ãƒ¼ã‚¹ã‚ãŸã‚Šä¸Šé™**: ç·è³‡é‡‘ã®5%ã¾ã§

### 6.3 ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè£…

```python
def backtest(predictions_df, initial_capital=100000):
    """
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    """
    capital = initial_capital
    history = []

    for race_id in predictions_df['race_id'].unique():
        race_data = predictions_df[predictions_df['race_id'] == race_id]

        # æŠ•è³‡å¯¾è±¡ã®é¦¬ã‚’é¸å®š
        race_data['expected_return'] = race_data['pred_prob'] * race_data['odds']
        bet_horses = race_data[race_data['expected_return'] > 1.2].copy()

        if len(bet_horses) == 0:
            continue

        # è³­ã‘é‡‘é…åˆ†
        for idx, row in bet_horses.iterrows():
            kelly_frac = fractional_kelly(row['pred_prob'], row['odds'])
            bet_amount = min(capital * kelly_frac, capital * 0.05)

            # çµæœåˆ¤å®š
            if row['finish_position'] <= 3:  # è¤‡å‹çš„ä¸­
                payout = bet_amount * row['place_odds']
                capital += (payout - bet_amount)
                result = 'win'
            else:
                capital -= bet_amount
                result = 'lose'

            history.append({
                'race_id': race_id,
                'horse_id': row['horse_id'],
                'bet_amount': bet_amount,
                'result': result,
                'capital': capital
            })

    return pd.DataFrame(history)
```

### 6.4 ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè©•ä¾¡æŒ‡æ¨™

```python
def backtest_metrics(history_df, initial_capital):
    """
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè©•ä¾¡æŒ‡æ¨™è¨ˆç®—
    """
    total_bet = history_df['bet_amount'].sum()
    total_return = history_df[history_df['result'] == 'win']['bet_amount'].sum()

    metrics = {
        'recovery_rate': (total_return / total_bet) * 100,
        'hit_rate': (len(history_df[history_df['result'] == 'win']) / len(history_df)) * 100,
        'final_capital': history_df['capital'].iloc[-1],
        'profit': history_df['capital'].iloc[-1] - initial_capital,
        'max_drawdown': calculate_max_drawdown(history_df['capital']),
        'sharpe_ratio': calculate_sharpe_ratio(history_df)
    }

    return metrics
```

---

## 7. é‹ç”¨ãƒ•ãƒ­ãƒ¼

### 7.1 æ—¥æ¬¡é‹ç”¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

#### 7.1.1 å‰æ—¥å‡¦ç† (PM 9:00)
1. **ãƒ‡ãƒ¼ã‚¿å–å¾—**: ç¿Œæ—¥ã®ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã€å‡ºèµ°é¦¬æƒ…å ±
2. **ç‰¹å¾´é‡ç”Ÿæˆ**: å‰æ—¥æ™‚ç‚¹ã§ä½œæˆå¯èƒ½ãªç‰¹å¾´é‡
3. **äºˆæ¸¬å®Ÿè¡Œ**: ç¿Œæ—¥å…¨ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬
4. **é€šçŸ¥**: Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–° + ãƒ¡ãƒ¼ãƒ«/LINEé€šçŸ¥

#### 7.1.2 å½“æ—¥å‡¦ç† (AM 8:00)
1. **ãƒ‡ãƒ¼ã‚¿æ›´æ–°**: å½“æ—¥ã®é¦¬å ´çŠ¶æ…‹ã€ã‚ªãƒƒã‚ºæƒ…å ±
2. **ç‰¹å¾´é‡æ›´æ–°**: ã‚ªãƒƒã‚ºé–¢é€£ç‰¹å¾´é‡
3. **äºˆæ¸¬æ›´æ–°**: æœ€æ–°æƒ…å ±ã§äºˆæ¸¬ã‚’å†å®Ÿè¡Œ
4. **é€šçŸ¥**: æ›´æ–°ã‚’Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ + ãƒ¡ãƒ¼ãƒ«/LINEé€šçŸ¥

### 7.2 äºˆæ¸¬å‡¦ç†ãƒ•ãƒ­ãƒ¼

```python
# prediction_pipeline.py

def daily_prediction_pipeline(target_date):
    """
    æ—¥æ¬¡äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
    race_info = fetch_race_info(target_date)
    horse_info = fetch_horse_info(target_date)

    # 2. ç‰¹å¾´é‡ç”Ÿæˆ
    features = generate_features(race_info, horse_info)

    # 3. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    model = load_model_from_gcs('gs://keiba-models/latest_model.txt')

    # 4. äºˆæ¸¬
    predictions = model.predict(features)

    # 5. æŠ•è³‡åˆ¤æ–­
    investment_plan = create_investment_plan(predictions, features)

    # 6. çµæœä¿å­˜
    save_predictions_to_bigquery(investment_plan)

    # 7. é€šçŸ¥
    send_notification(investment_plan)

    return investment_plan
```

### 7.3 Cloud Runãƒ‡ãƒ—ãƒ­ã‚¤

#### 7.3.1 Dockerfile
```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "prediction_pipeline.py"]
```

#### 7.3.2 ãƒ‡ãƒ—ãƒ­ã‚¤ã‚³ãƒãƒ³ãƒ‰
```bash
# ãƒ“ãƒ«ãƒ‰ & ãƒ‡ãƒ—ãƒ­ã‚¤
gcloud builds submit --tag gcr.io/PROJECT_ID/prediction-service
gcloud run deploy prediction-service \
  --image gcr.io/PROJECT_ID/prediction-service \
  --platform managed \
  --region asia-northeast1 \
  --memory 2Gi \
  --timeout 900
```

---

## 8. Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

### 8.1 æ©Ÿèƒ½è¦ä»¶

#### 8.1.1 ç”»é¢æ§‹æˆ
1. **ãƒ›ãƒ¼ãƒ **: å½“æ—¥ãƒ»ç¿Œæ—¥ã®ãŠã™ã™ã‚é¦¬åˆ¸
2. **ãƒ¬ãƒ¼ã‚¹ä¸€è¦§**: å…¨ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬çµæœ
3. **ãƒ¬ãƒ¼ã‚¹è©³ç´°**: å„é¦¬ã®äºˆæ¸¬ç¢ºç‡ã€ã‚ªãƒƒã‚ºã€æœŸå¾…å€¤
4. **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**: éå»ã®æˆç¸¾ã€å›åç‡æ¨ç§»
5. **ãƒ¢ãƒ‡ãƒ«æƒ…å ±**: ç‰¹å¾´é‡é‡è¦åº¦ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½

#### 8.1.2 å®Ÿè£… (Streamlit)

```python
# dashboard.py

import streamlit as st
import pandas as pd

def main():
    st.title("ç«¶é¦¬äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    menu = st.sidebar.selectbox(
        "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
        ["ãƒ›ãƒ¼ãƒ ", "ãƒ¬ãƒ¼ã‚¹ä¸€è¦§", "ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ", "ãƒ¢ãƒ‡ãƒ«æƒ…å ±"]
    )

    if menu == "ãƒ›ãƒ¼ãƒ ":
        show_home()
    elif menu == "ãƒ¬ãƒ¼ã‚¹ä¸€è¦§":
        show_race_list()
    elif menu == "ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ":
        show_backtest()
    elif menu == "ãƒ¢ãƒ‡ãƒ«æƒ…å ±":
        show_model_info()

def show_home():
    st.header("æœ¬æ—¥ã®ãŠã™ã™ã‚é¦¬åˆ¸")

    # BigQueryã‹ã‚‰äºˆæ¸¬çµæœå–å¾—
    predictions = fetch_today_predictions()

    # TOP3è¡¨ç¤º
    top_bets = predictions.nlargest(3, 'expected_return')

    for idx, row in top_bets.iterrows():
        with st.expander(f"{row['venue']} {row['race_number']}R - {row['horse_name']}"):
            col1, col2, col3 = st.columns(3)
            col1.metric("äºˆæ¸¬ç¢ºç‡", f"{row['pred_prob']:.1%}")
            col2.metric("ã‚ªãƒƒã‚º", f"{row['odds']:.1f}")
            col3.metric("æœŸå¾…å›åç‡", f"{row['expected_return']:.2f}")

            st.write(f"æ¨å¥¨æŠ•è³‡é¡: Â¥{row['recommended_bet']:,.0f}")

def show_race_list():
    # å®Ÿè£…...
    pass

if __name__ == "__main__":
    main()
```

---

## 9. é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

### 9.1 ãƒ¡ãƒ¼ãƒ«é€šçŸ¥

#### 9.1.1 SendGridå®Ÿè£…
```python
# notification.py

from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail

def send_email_notification(predictions_df):
    """
    äºˆæ¸¬çµæœã‚’ãƒ¡ãƒ¼ãƒ«é€šçŸ¥
    """
    top_bets = predictions_df.nlargest(5, 'expected_return')

    html_content = f"""
    <h2>æœ¬æ—¥ã®ãŠã™ã™ã‚é¦¬åˆ¸</h2>
    <table>
        <tr>
            <th>ãƒ¬ãƒ¼ã‚¹</th>
            <th>é¦¬å</th>
            <th>äºˆæ¸¬ç¢ºç‡</th>
            <th>ã‚ªãƒƒã‚º</th>
            <th>æœŸå¾…å›åç‡</th>
        </tr>
    """

    for idx, row in top_bets.iterrows():
        html_content += f"""
        <tr>
            <td>{row['venue']} {row['race_number']}R</td>
            <td>{row['horse_name']}</td>
            <td>{row['pred_prob']:.1%}</td>
            <td>{row['odds']:.1f}</td>
            <td>{row['expected_return']:.2f}</td>
        </tr>
        """

    html_content += "</table>"

    message = Mail(
        from_email='noreply@keiba-prediction.com',
        to_emails='user@example.com',
        subject='ç«¶é¦¬äºˆæ¸¬: æœ¬æ—¥ã®ãŠã™ã™ã‚é¦¬åˆ¸',
        html_content=html_content
    )

    sg = SendGridAPIClient(os.environ.get('SENDGRID_API_KEY'))
    response = sg.send(message)
```

### 9.2 LINEé€šçŸ¥

#### 9.2.1 LINE Notifyå®Ÿè£…
```python
import requests

def send_line_notification(predictions_df):
    """
    äºˆæ¸¬çµæœã‚’LINEé€šçŸ¥
    """
    top_bets = predictions_df.nlargest(3, 'expected_return')

    message = "ğŸ‡ æœ¬æ—¥ã®ãŠã™ã™ã‚é¦¬åˆ¸\n\n"

    for idx, row in top_bets.iterrows():
        message += f"{row['venue']} {row['race_number']}R\n"
        message += f"é¦¬å: {row['horse_name']}\n"
        message += f"äºˆæ¸¬: {row['pred_prob']:.1%} / ã‚ªãƒƒã‚º: {row['odds']:.1f}\n"
        message += f"æœŸå¾…å›åç‡: {row['expected_return']:.2f}\n\n"

    url = "https://notify-api.line.me/api/notify"
    headers = {
        "Authorization": f"Bearer {os.environ.get('LINE_NOTIFY_TOKEN')}"
    }
    data = {"message": message}

    response = requests.post(url, headers=headers, data=data)
```

---

## 10. å®Ÿè£…è¨ˆç”»

### 10.1 Phase 1: ãƒ‡ãƒ¼ã‚¿åŸºç›¤æ§‹ç¯‰ (2é€±é–“)

#### Week 1
- [ ] GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆã€æ¨©é™è¨­å®š
- [ ] GCSãƒã‚±ãƒƒãƒˆä½œæˆ
- [ ] BigQueryãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«â†’GCSè‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- [ ] GCSâ†’BigQueryè‡ªå‹•ãƒ­ãƒ¼ãƒ‰Cloud Functions

#### Week 2
- [ ] æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ­ãƒ¼ãƒ‰
- [ ] ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
- [ ] BigQuery SQLã§ã®ãƒ‡ãƒ¼ã‚¿é›†è¨ˆç¢ºèª

### 10.2 Phase 2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (3-4é€±é–“)

#### Week 3-4
- [ ] Phase 1ç‰¹å¾´é‡å®Ÿè£… (éå»èµ°é›†è¨ˆã€æ¡ä»¶é©æ€§)
- [ ] Jupyter Notebookã§EDA
- [ ] ç‰¹å¾´é‡ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…
- [ ] BigQueryã«ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ

#### Week 5-6
- [ ] Phase 2ç‰¹å¾´é‡å®Ÿè£… (Target Encodingã€å±•é–‹äºˆæ¸¬)
- [ ] ç‰¹å¾´é‡æ¤œè¨¼ (ãƒªãƒ¼ã‚¯ç¢ºèª)
- [ ] ç‰¹å¾´é‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ

### 10.3 Phase 3: ãƒ¢ãƒ‡ãƒ«é–‹ç™º (2-3é€±é–“)

#### Week 7-8
- [ ] LightGBM ãƒ©ãƒ³ã‚¯å­¦ç¿’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
- [ ] æ™‚ç³»åˆ—CVã§ã®è©•ä¾¡
- [ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

#### Week 9
- [ ] ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè£…
- [ ] æŠ•è³‡æˆ¦ç•¥æ¤œè¨¼
- [ ] ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ

### 10.4 Phase 4: é‹ç”¨ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ (2-3é€±é–“)

#### Week 10-11
- [ ] äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…
- [ ] Cloud Runãƒ‡ãƒ—ãƒ­ã‚¤
- [ ] Cloud Schedulerè¨­å®š
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒ­ã‚°å®Ÿè£…

#### Week 12
- [ ] Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å®Ÿè£… (Streamlit)
- [ ] ãƒ¡ãƒ¼ãƒ«/LINEé€šçŸ¥å®Ÿè£…
- [ ] çµåˆãƒ†ã‚¹ãƒˆ

### 10.5 Phase 5: é‹ç”¨é–‹å§‹ (ç¶™ç¶š)

- [ ] æœ¬ç•ªé‹ç”¨é–‹å§‹
- [ ] æ—¥æ¬¡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- [ ] é€±æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] æœˆæ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’

---

## 11. ãƒªã‚¹ã‚¯ç®¡ç†

### 11.1 æŠ€è¡“çš„ãƒªã‚¹ã‚¯

| ãƒªã‚¹ã‚¯ | å¯¾ç­– |
|--------|------|
| ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œ | ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ç•°å¸¸å€¤æ¤œçŸ¥ |
| ãƒ¢ãƒ‡ãƒ«éå­¦ç¿’ | æ™‚ç³»åˆ—CVã€æ­£å‰‡åŒ–ã€Early Stopping |
| ãƒªãƒ¼ã‚¯ | ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ä½“åˆ¶ |
| äºˆæ¸¬é…å»¶ | ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã€éåŒæœŸå‡¦ç† |

### 11.2 é‹ç”¨ãƒªã‚¹ã‚¯

| ãƒªã‚¹ã‚¯ | å¯¾ç­– |
|--------|------|
| GCPã‚³ã‚¹ãƒˆè¶…é | äºˆç®—ã‚¢ãƒ©ãƒ¼ãƒˆã€ã‚¯ã‚¨ãƒªæœ€é©åŒ– |
| ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åŠ£åŒ– | ç¶™ç¶šçš„ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã€æœˆæ¬¡å†å­¦ç¿’ |
| ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— | ãƒªãƒˆãƒ©ã‚¤å‡¦ç†ã€ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ |

### 11.3 æŠ•è³‡ãƒªã‚¹ã‚¯

| ãƒªã‚¹ã‚¯ | å¯¾ç­– |
|--------|------|
| é€£ç¶šæå¤± | 1æ—¥ã‚ãŸã‚ŠæŠ•è³‡ä¸Šé™ã€Fractional Kelly |
| éåº¦ãªè³­ã‘ | KellyåŸºæº–ã€1ãƒ¬ãƒ¼ã‚¹ã‚ãŸã‚Šä¸Šé™ |
| äºˆæ¸¬ç²¾åº¦ä½ä¸‹ | ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç¶™ç¶šã€é–¾å€¤èª¿æ•´ |

---

## 12. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»æ”¹å–„

### 12.1 KPI

| æŒ‡æ¨™ | ç›®æ¨™ | æ¸¬å®šé »åº¦ |
|------|------|----------|
| å›åç‡ | 100%ä»¥ä¸Š | é€±æ¬¡ |
| çš„ä¸­ç‡ | 30%ä»¥ä¸Š | é€±æ¬¡ |
| NDCG@3 | 0.7ä»¥ä¸Š | æœˆæ¬¡ |
| Recall@3 | 0.8ä»¥ä¸Š | æœˆæ¬¡ |

### 12.2 æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«

1. **æ—¥æ¬¡**: äºˆæ¸¬çµæœã¨å®Ÿç¸¾ã®æ¯”è¼ƒ
2. **é€±æ¬¡**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€é–¾å€¤èª¿æ•´
3. **æœˆæ¬¡**: ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ã€ç‰¹å¾´é‡è¿½åŠ æ¤œè¨
4. **å››åŠæœŸ**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¦‹ç›´ã—

---

## 13. å‚è€ƒè³‡æ–™

### 13.1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- `ML_FEATURE.md`: ç‰¹å¾´é‡è¨­è¨ˆè©³ç´°
- `downloader/README.md`: ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †

### 13.2 å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹
- JRDBå…¬å¼: http://www.jrdb.com/
- LightGBM Documentation: https://lightgbm.readthedocs.io/
- GCP Documentation: https://cloud.google.com/docs

---

## ä»˜éŒ²A: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
keiba_prediction/
â”œâ”€â”€ downloader/              # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ download_from_date.sh
â”‚   â”œâ”€â”€ download_all_from_date.sh
â”‚   â””â”€â”€ ...
â”œâ”€â”€ downloaded_files/        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ (gitignore)
â”œâ”€â”€ notebooks/               # Jupyter Notebook (EDA)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_model_training.ipynb
â”œâ”€â”€ src/                     # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ download.py      # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
â”‚   â”‚   â”œâ”€â”€ upload_to_gcs.py # GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
â”‚   â”‚   â””â”€â”€ load_to_bq.py    # BigQueryãƒ­ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ base_features.py
â”‚   â”‚   â”œâ”€â”€ target_encoding.py
â”‚   â”‚   â””â”€â”€ feature_pipeline.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ lgbm_ranker.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â”œâ”€â”€ backtest/
â”‚   â”‚   â”œâ”€â”€ simulator.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ prediction_service.py
â”‚   â”‚   â””â”€â”€ dashboard.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ notification.py
â”œâ”€â”€ cloud_functions/         # Cloud Functions
â”‚   â”œâ”€â”€ gcs_to_bq/
â”‚   â””â”€â”€ notification/
â”œâ”€â”€ tests/                   # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_backtest.py
â”œâ”€â”€ config/                  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ bq_schema.json
â”‚   â””â”€â”€ model_config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CLAUDE.md               # æœ¬ä»•æ§˜æ›¸
â”œâ”€â”€ ML_FEATURE.md           # ç‰¹å¾´é‡è¨­è¨ˆ
â””â”€â”€ README.md
```

---

## ä»˜éŒ²B: ç’°å¢ƒå¤‰æ•°

```bash
# .env.example

# GCP
GCP_PROJECT_ID=your-project-id
GCP_REGION=asia-northeast1
GCS_BUCKET_RAW=keiba-raw-data
GCS_BUCKET_MODELS=keiba-models

# BigQuery
BQ_DATASET_RAW=raw
BQ_DATASET_FEATURES=features
BQ_DATASET_PREDICTIONS=predictions

# JRDB
JRDB_USER=your-jrdb-user
JRDB_PASSWORD=your-jrdb-password

# Notification
SENDGRID_API_KEY=your-sendgrid-key
LINE_NOTIFY_TOKEN=your-line-token

# Model
MODEL_VERSION=v1.0.0
PREDICTION_THRESHOLD=0.3
```

---

## å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ | æ‹…å½“è€… |
|------|-----------|----------|--------|
| 2026-01-18 | 1.0.0 | åˆç‰ˆä½œæˆ | Claude |

---

**End of Document**
